{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Loading Datasets (tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_phrase(flist):\n",
    "    plist = []\n",
    "    if len(flist) > 0:\n",
    "        for feature in flist:\n",
    "            feature = re.sub('[_]',' ',feature)\n",
    "            feature = feature.strip()\n",
    "            feature_p = ''.join(feature.split(' '))\n",
    "            plist.append(feature_p)\n",
    "    return plist\n",
    "\n",
    "def list_to_string(flist):\n",
    "    string = ' '.join(flist)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_train = pd.read_json('train.json.zip', orient='columns', convert_dates=['created'], compression='zip')\n",
    "ori_train = ori_train.reset_index()\n",
    "ori_train.rename(columns={'index':'rec_id'}, inplace=True) \n",
    "train = ori_train\n",
    "test =  pd.read_json('test.json.zip', orient='columns', convert_dates=['created'], compression='zip')\n",
    "test = test.reset_index()\n",
    "test.rename(columns={'index':'rec_id'}, inplace=True)\n",
    "\n",
    "# remove outliers with ridiculously high prices\n",
    "train = train[train['price']<=20000]\n",
    "# remove outliers which the houses locate far away from most of the houses and missing values\n",
    "train = train[(train['latitude'] <= 41.5) & (train['latitude'] >= 40) & (train['longitude'] >= -80) & (train['longitude'] <= -70)]\n",
    "# remove outliers which have bathrooms more than bedrooms\n",
    "train['diff_rooms'] = train['bedrooms'] - train['bathrooms']\n",
    "train = train[train['diff_rooms']>=-1.5]\n",
    "\n",
    "train_text = train[['description', 'features']]\n",
    "test_text = test[['description', 'features']]\n",
    "data_text = pd.concat([train_text, test_text], axis=0)\n",
    "\n",
    "# tfidf\n",
    "desc_tfidf = TfidfVectorizer(min_df=20, max_features=40, strip_accents='unicode',lowercase =True,\n",
    "                        analyzer='word', token_pattern=r'\\w{5,}', ngram_range=(1, 3),  sublinear_tf=True, stop_words = 'english')  \n",
    "desc_tfidf_fit =desc_tfidf.fit_transform(data_text['description'])\n",
    "desc_name = [x for x in desc_tfidf.get_feature_names()]\n",
    "# standardize \"feature\"\n",
    "data_text['features_phr'] = data_text['features'].apply(word_to_phrase)\n",
    "data_text['features_phr_str'] = data_text['features_phr'].apply(list_to_string)\n",
    "# tfidf 'feature'\n",
    "phr_tfidf = TfidfVectorizer(min_df=2, max_features=40, strip_accents='unicode', lowercase=True, token_pattern=r'\\w{3,}', stop_words='english')  \n",
    "phr_tfidf_fit =phr_tfidf.fit_transform(data_text['features_phr_str'])\n",
    "phr_names = [x for x in phr_tfidf.get_feature_names()]\n",
    "data_text['features_phr_vec'] = pd.Series(phr_tfidf_fit.toarray().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phr_list = phr_tfidf_fit.toarray().tolist()\n",
    "p_array=np.asarray(phr_list).reshape(123824, 40)\n",
    "phr = pd.DataFrame(p_array, columns=[\"p_%d\" % i for i in range(0, 40)])\n",
    "\n",
    "desc_list = desc_tfidf_fit.toarray().tolist()\n",
    "d_array=np.asarray(desc_list).reshape(123824, 40)\n",
    "desc = pd.DataFrame(d_array, columns=[\"d_%d\" % i for i in range(0, 40)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_0</th>\n",
       "      <th>p_1</th>\n",
       "      <th>p_2</th>\n",
       "      <th>p_3</th>\n",
       "      <th>p_4</th>\n",
       "      <th>p_5</th>\n",
       "      <th>p_6</th>\n",
       "      <th>p_7</th>\n",
       "      <th>p_8</th>\n",
       "      <th>p_9</th>\n",
       "      <th>...</th>\n",
       "      <th>d_30</th>\n",
       "      <th>d_31</th>\n",
       "      <th>d_32</th>\n",
       "      <th>d_33</th>\n",
       "      <th>d_34</th>\n",
       "      <th>d_35</th>\n",
       "      <th>d_36</th>\n",
       "      <th>d_37</th>\n",
       "      <th>d_38</th>\n",
       "      <th>d_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505923</td>\n",
       "      <td>0.288970</td>\n",
       "      <td>0.280043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194602</td>\n",
       "      <td>0.228802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410219</td>\n",
       "      <td>0.360214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382540</td>\n",
       "      <td>0.335909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182340</td>\n",
       "      <td>0.340825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155577</td>\n",
       "      <td>0.161545</td>\n",
       "      <td>0.173477</td>\n",
       "      <td>0.159496</td>\n",
       "      <td>0.172502</td>\n",
       "      <td>0.109952</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>0.299960</td>\n",
       "      <td>0.191192</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474337</td>\n",
       "      <td>0.416516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123819</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123820</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360240</td>\n",
       "      <td>0.349111</td>\n",
       "      <td>0.358902</td>\n",
       "      <td>0.315153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245978</td>\n",
       "      <td>0.219085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148325</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123821</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191186</td>\n",
       "      <td>0.224785</td>\n",
       "      <td>0.183148</td>\n",
       "      <td>0.190173</td>\n",
       "      <td>0.204220</td>\n",
       "      <td>0.187761</td>\n",
       "      <td>0.203073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123822</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513247</td>\n",
       "      <td>0.527642</td>\n",
       "      <td>0.463324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123823</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252330</td>\n",
       "      <td>0.244535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207759</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123824 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        p_0       p_1  p_2       p_3       p_4       p_5       p_6       p_7  \\\n",
       "0       0.0  0.269246  0.0  0.505923  0.288970  0.280043  0.000000  0.000000   \n",
       "1       0.0  0.000000  0.0  0.000000  0.411748  0.000000  0.410219  0.360214   \n",
       "2       0.0  0.000000  0.0  0.000000  0.383966  0.000000  0.382540  0.335909   \n",
       "3       0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4       0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.474337  0.416516   \n",
       "...     ...       ...  ...       ...       ...       ...       ...       ...   \n",
       "123819  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "123820  0.0  0.335651  0.0  0.000000  0.360240  0.349111  0.358902  0.315153   \n",
       "123821  0.0  0.693074  0.0  0.000000  0.000000  0.720867  0.000000  0.000000   \n",
       "123822  0.0  0.493459  0.0  0.000000  0.000000  0.513247  0.527642  0.463324   \n",
       "123823  0.0  0.235107  0.0  0.000000  0.252330  0.244535  0.000000  0.000000   \n",
       "\n",
       "        p_8  p_9  ...      d_30      d_31      d_32      d_33      d_34  \\\n",
       "0       0.0  0.0  ...  0.000000  0.194602  0.228802  0.000000  0.000000   \n",
       "1       0.0  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2       0.0  0.0  ...  0.182340  0.340825  0.000000  0.155577  0.161545   \n",
       "3       0.0  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4       0.0  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...     ...  ...  ...       ...       ...       ...       ...       ...   \n",
       "123819  0.0  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "123820  0.0  0.0  ...  0.245978  0.219085  0.000000  0.000000  0.000000   \n",
       "123821  0.0  0.0  ...  0.000000  0.191186  0.224785  0.183148  0.190173   \n",
       "123822  0.0  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "123823  0.0  0.0  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            d_35      d_36      d_37      d_38  d_39  \n",
       "0       0.000000  0.000000  0.000000  0.131750   0.0  \n",
       "1       0.000000  0.000000  0.000000  0.186830   0.0  \n",
       "2       0.173477  0.159496  0.172502  0.109952   0.0  \n",
       "3       0.000000  0.277344  0.299960  0.191192   0.0  \n",
       "4       0.000000  0.000000  0.000000  0.382024   0.0  \n",
       "...          ...       ...       ...       ...   ...  \n",
       "123819  0.000000  0.000000  0.000000  0.000000   0.0  \n",
       "123820  0.000000  0.000000  0.000000  0.148325   0.0  \n",
       "123821  0.204220  0.187761  0.203073  0.000000   0.0  \n",
       "123822  0.000000  0.000000  0.000000  0.000000   0.0  \n",
       "123823  0.000000  0.000000  0.000000  0.207759   0.0  \n",
       "\n",
       "[123824 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = phr.join([desc])\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Drop correlated columns and less significant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(X):\n",
    "    corr_threshold = 0.9\n",
    "    corr = X.corr()\n",
    "    drop_columns = np.full(corr.shape[0], False, dtype=bool)\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i + 1, corr.shape[0]):\n",
    "            if corr.iloc[i, j] >= corr_threshold:\n",
    "                drop_columns[j] = True\n",
    "    columns_dropped = X.columns[drop_columns]\n",
    "    X.drop(columns_dropped, axis=1, inplace=True)\n",
    "    return columns_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_less_significant_features(X, Y):\n",
    "    sl = 0.05\n",
    "    regression_ols = None\n",
    "    columns_dropped = np.array([])\n",
    "    for itr in range(0, len(X.columns)):\n",
    "        regression_ols = sm.OLS(Y, X).fit()\n",
    "        max_col = regression_ols.pvalues.idxmax()\n",
    "        max_val = regression_ols.pvalues.max()\n",
    "        if max_val > sl:\n",
    "            X.drop(max_col, axis='columns', inplace=True)\n",
    "            columns_dropped = np.append(columns_dropped, [max_col])\n",
    "        else:\n",
    "            break\n",
    "    regression_ols.summary()\n",
    "    return columns_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dropped_corr = remove_correlated_features(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p_24', 'p_29', 'p_35', 'p_38', 'd_19', 'd_29', 'd_34', 'd_36', 'd_37'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_dropped_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_train=pd.read_json(\"modified_data/modified_train.json\")\n",
    "ori_test = pd.read_json(\"modified_data/modified_test.json\")\n",
    "\n",
    "ori_train = ori_train.drop(columns=['rec_id', 'building_id','description','display_address','manager_id','features','photos','street_address','features_phr_vec','description_vec','text_vec'])\n",
    "ori_train = ori_train.reset_index()\n",
    "train = ori_train.join(text)\n",
    "\n",
    "ori_test = ori_test.drop(columns=['rec_id', 'building_id','description','display_address','manager_id','features','photos','street_address','features_phr_vec','description_vec','text_vec'])\n",
    "ori_test = ori_test.reset_index()\n",
    "test = ori_test.join(text)\n",
    "\n",
    "Listing_id_train = train['listing_id']\n",
    "y_train = train['interest_level']\n",
    "X_train = train.drop(columns=['index','listing_id', 'interest_level', 'diff_rooms'])\n",
    "\n",
    "Listing_id_test = test['listing_id']\n",
    "X_test = test.drop(columns=['index', 'listing_id'])\n",
    "\n",
    "y_train_map = {\"low\":0, \"medium\": 1, \"high\": 2}\n",
    "y_train = y_train.map(y_train_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:49165]\n",
    "X_test = X[49165:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xixi6\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py:3987: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['d_1', 'p_21', 'd_4', 'p_20', 'd_9', 'p_25', 'p_1', 'p_0', 'd_26',\n",
       "       'd_5', 'd_10', 'd_27', 'd_15', 'd_2', 'created', 'd_11', 'd_33',\n",
       "       'd_35', 'p_13', 'd_17', 'd_16', 'p_12', 'manager_id_num'],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_dropped_insig = remove_less_significant_features(X_train, y_train)\n",
    "X_sig = X.drop(columns=columns_dropped_insig)\n",
    "columns_dropped_insig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Data Reduction - PCA & Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply PCA\n",
    "X_pca = PCA(n_components=6).fit_transform(X)\n",
    "X_train_pca = X_pca[:49165]\n",
    "X_test_pca = X_pca[49165:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_pca)\n",
    "X_train_scaled = X_scaled[:49165]\n",
    "X_test_scaled = X_scaled[49165:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cross-validation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "def crossValidation(clf, X, y, n):\n",
    "    cv = KFold(n_splits=n)\n",
    "    y_pred = []\n",
    "    i=0\n",
    "    # split the training data to training and validation data\n",
    "    for train_index, valid_index in cv.split(X):\n",
    "        print(\"loop %d\" % i)\n",
    "        i += 1\n",
    "        X_tr, X_va, y_tr, y_va = X[train_index], X[valid_index], y.iloc[train_index], y.iloc[valid_index]\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        y_pred.append(clf.predict(X_va))\n",
    "        newScore = clf.score(X_va, y_va)\n",
    "        scores.append(newScore)\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "n_estimators = 10\n",
    "clf = OneVsRestClassifier(BaggingClassifier(SVC(kernel='sigmoid',C=1, gamma='auto', probability=True, class_weight='balanced'), max_samples=1.0/ n_estimators, n_estimators=n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 0\n",
      "loop 1\n",
      "loop 2\n",
      "loop 3\n",
      "loop 4\n"
     ]
    }
   ],
   "source": [
    "y_pred = crossValidation(clf, X_train_scaled, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_array = np.asarray(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.468606 (+/- 0.035354)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores_array.mean(), scores_array.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import time\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def tuneParameters(X, y, tuned_parameters, X_test):\n",
    "    score = 'accuracy'\n",
    "    \n",
    "    print('# Tuning hyper-parameters for %s' % score)\n",
    "    print()\n",
    "    n_estimators=10\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    grid = GridSearchCV(SVC(probability=True, class_weight='balanced', cache_size=10000), param_grid=tuned_parameters,scoring='accuracy', cv=cv)\n",
    "    \n",
    "    grid.fit(X, y)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grid.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = grid.cv_results_['mean_test_score']\n",
    "    stds = grid.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "\n",
    "    return grid.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'kernel': ['linear'], 'C': [1,100]}]\n",
    "\n",
    "y_test = tuneParameters(X_train_scaled, y_train, tuned_parameters, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Further improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Bagging in SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def bagging(X, y, X_test):\n",
    "    n_estimators = 10\n",
    "    start = time.time()\n",
    "    clf = OneVsRestClassifier(BaggingClassifier(SVC(kernel='linear',C=10, probability=True, class_weight='balanced'), max_samples=1.0/ n_estimators, n_estimators=n_estimators))\n",
    "    clf.fit(X, y)\n",
    "    end = time.time()\n",
    "    print(\"Bagging SVC:\", end - start, clf.score(X,y))\n",
    "    return clf.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging here helps improve the efficiency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear kernel with C=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging SVC: 59.25253129005432 0.6937455506966338\n"
     ]
    }
   ],
   "source": [
    "y_test = bagging(X_train_scaled, y_train, X_test_scaled, 'linear', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the order of columns in result\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "cols = y_test_df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "y_test = y_test_df[cols].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_result_format(X):\n",
    "    res = pd.DataFrame(y_test,columns=['high', 'low', 'medium'])\n",
    "    temp = res['low']\n",
    "    res = res.drop(columns = {'low'})\n",
    "    res.insert(2,'low',temp)\n",
    "    res.insert\n",
    "    res.insert(0,'listing_id',X['listing_id'])\n",
    "    res.to_csv('submission.csv', index = None)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.DataFrame(X_test).join([Listing_id_test])\n",
    "res = to_result_format(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>high</th>\n",
       "      <th>medium</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7142618</td>\n",
       "      <td>0.081533</td>\n",
       "      <td>0.227132</td>\n",
       "      <td>0.691335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7210040</td>\n",
       "      <td>0.083058</td>\n",
       "      <td>0.226309</td>\n",
       "      <td>0.690633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7174566</td>\n",
       "      <td>0.082346</td>\n",
       "      <td>0.227387</td>\n",
       "      <td>0.690267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7191391</td>\n",
       "      <td>0.082670</td>\n",
       "      <td>0.226395</td>\n",
       "      <td>0.690935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7171695</td>\n",
       "      <td>0.082036</td>\n",
       "      <td>0.226435</td>\n",
       "      <td>0.691529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74654</th>\n",
       "      <td>6928108</td>\n",
       "      <td>0.077813</td>\n",
       "      <td>0.234572</td>\n",
       "      <td>0.687615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74655</th>\n",
       "      <td>6906674</td>\n",
       "      <td>0.076642</td>\n",
       "      <td>0.232124</td>\n",
       "      <td>0.691233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74656</th>\n",
       "      <td>6897967</td>\n",
       "      <td>0.077122</td>\n",
       "      <td>0.234780</td>\n",
       "      <td>0.688098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74657</th>\n",
       "      <td>6842183</td>\n",
       "      <td>0.075041</td>\n",
       "      <td>0.231113</td>\n",
       "      <td>0.693846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74658</th>\n",
       "      <td>6889319</td>\n",
       "      <td>0.076290</td>\n",
       "      <td>0.232049</td>\n",
       "      <td>0.691661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74659 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       listing_id      high    medium       low\n",
       "0         7142618  0.081533  0.227132  0.691335\n",
       "1         7210040  0.083058  0.226309  0.690633\n",
       "2         7174566  0.082346  0.227387  0.690267\n",
       "3         7191391  0.082670  0.226395  0.690935\n",
       "4         7171695  0.082036  0.226435  0.691529\n",
       "...           ...       ...       ...       ...\n",
       "74654     6928108  0.077813  0.234572  0.687615\n",
       "74655     6906674  0.076642  0.232124  0.691233\n",
       "74656     6897967  0.077122  0.234780  0.688098\n",
       "74657     6842183  0.075041  0.231113  0.693846\n",
       "74658     6889319  0.076290  0.232049  0.691661\n",
       "\n",
       "[74659 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logloss=0.79002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSVC(X, y, clfs, titles):\n",
    "    # create a mesh to plot in\n",
    "    x_min, x_max = X[:, 0].min() -1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    h = (x_max - x_min)/100\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "    for i, clf in enumerate(clfs):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        #print(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "        plt.xlabel('Sepal length')\n",
    "        plt.ylabel('Sepal width')\n",
    "        plt.xlim(xx.min(), xx.max())\n",
    "        plt.ylim(yy.min(), yy.max())\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.title(titles[i])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = np.asarray(y_pred).reshape(49165,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "def cm_plot(y_valid,y_pred):\n",
    "    cm = confusion_matrix(y_valid, y_pred, labels = [0,1,2])\n",
    "    cm = pd.DataFrame(cm,columns=['low','medium','high'],index = ['low','medium','high'])\n",
    "    plt.title('Confusion Matrix',fontsize=18)\n",
    "    ax = sns.heatmap(cm,annot=True,cmap='YlGn_r',fmt='.20g',linewidths = 0)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    plt.xlabel('Predicted Label',fontsize=12)\n",
    "    plt.ylabel('True Label',fontsize=12)\n",
    "    plt.savefig('cm.png',dpi=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot(y_valid, y_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
